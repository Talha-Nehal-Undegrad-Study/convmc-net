{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QkewbYGcurVf",
    "outputId": "4a84caab-79f0-4e45-bd04-b374a9fcb32b"
   },
   "outputs": [],
   "source": [
    "# Deep Learning Libraries\n",
    "# !pip install 'torch==2.0.1+cu117' -f https://download.pytorch.org/whl/torch_stable.html\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Data Manipulation and Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections # A module providing alternative data structures like named tuples, defaultdict, Counter, etc., compared to built-in Python containers.\n",
    "import random\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "# File and System Interaction\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Scientific Computing and Math\n",
    "import scipy\n",
    "from scipy.signal import tukey # A function from SciPy used to generate a Tukey window for signal processing.\n",
    "from scipy.io import loadmat # A function from SciPy used for reading MATLAB data files.\n",
    "import scipy.io as sio # The SciPy I/O module providing functions for working with different file formats.\n",
    "import math\n",
    "import cmath\n",
    "\n",
    "# # Google Colab and Mount Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Date and Time Handling\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Linear Algebra\n",
    "from torch import linalg as LA\n",
    "import importlib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_py_scripts import convmc, dataset_processing, logs_and_results, training, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up some global variables\n",
    "\n",
    "# ROOT = '/home/gcf/Desktop/Talha_Nehal Sproj/Tahir Sproj Stuff/SPROJ_ConvMC_Net/Sensor_Data'\n",
    "\n",
    "ROOT = 'C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/convmc-net/'\n",
    "\n",
    "# For synthetic\n",
    "# DATA_PATH = ROOT + '/Synthetic_Image_Inpainting_Dataset'\n",
    "\n",
    "# For Image Data\n",
    "template = 'C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/convmc-net/Image_Inpainting_Data/BSDS300/images'\n",
    "DATA_PATH = 'C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/convmc-net/Image_Inpainting_Data/BSDS300/images'\n",
    "'C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/convmc-net/Image_Inpainting_Data/BSDS300/images'\n",
    "\n",
    "TRY = '1st_try'\n",
    "SESSION = 'Session_1'\n",
    "\n",
    "sys.path.append(ROOT + 'image_py_scripts')\n",
    "\n",
    "# path = 'C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/convmc-net/Image_Inpainting_Data/BSDS300/images/Q 20.0%/DB 5.0/Saved Models - Whole/ConvMC-Net/Session_1/ConvMC-Net_Sampling20.0%_GMM5.0_Layers_5_TrainInstances_20_Epochs_[1_out_of_2]_lr_0.12.pth'\n",
    "\n",
    "# # Define a simple neural network model\n",
    "# class SimpleModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SimpleModel, self).__init__()\n",
    "#         self.fc1 = nn.Linear(10, 5)\n",
    "#         self.fc2 = nn.Linear(5, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# # Instantiate the model\n",
    "# model = SimpleModel()\n",
    "\n",
    "# # Specify the path to save the model\n",
    "\n",
    "# # Example input tensor (batch_size, input_size)\n",
    "# input_tensor = torch.randn(1, 10)\n",
    "\n",
    "# # Forward pass to initialize model parameters\n",
    "# output_tensor = model(input_tensor)\n",
    "\n",
    "# # Save the model to the specified path\n",
    "# torch.save(model.state_dict(), gg)\n",
    "\n",
    "# # Optionally, load the model from the saved path\n",
    "# # loaded_model = SimpleModel()\n",
    "# # loaded_model.load_state_dict(torch.load(save_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'image_py_scripts.training' from 'c:\\\\Users\\\\Talha\\\\OneDrive - Higher Education Commission\\\\Documents\\\\GitHub\\\\convmc-net\\\\image_py_scripts\\\\training.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importlib.reload(convmc)\n",
    "importlib.reload(training)\n",
    "# importlib.reload(logs_and_results)\n",
    "# importlib.reload(dataset_processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGsjtUu7-iJ5"
   },
   "source": [
    "Testing Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nOIBCr5gIr8Y"
   },
   "outputs": [],
   "source": [
    "# Get parameters\n",
    "def get_default_param(hyper_param_net, gpu = True):\n",
    "    params_net = {}\n",
    "    if hyper_param_net['Model'] == 'ADMM-Net':\n",
    "        params_net['layers'] = 5\n",
    "\n",
    "        params_net['initial_neta'] = 1.81    # fixed\n",
    "        params_net['initial_lamda1'] = 0.051 # fixed\n",
    "        params_net['initial_lamda2'] = 0.049 # fixed\n",
    "        params_net['initial_v'] = 0\n",
    "\n",
    "        params_net['initial_S'] = 0.05001 #fixed\n",
    "\n",
    "        params_net['initial_P'] = 0.2401 #fixed\n",
    "\n",
    "        params_net['initial_rho'] = 0.1001\n",
    "\n",
    "        params_net['coef_gamma'] = 0.4001\n",
    "\n",
    "        params_net['CalInGPU'] = gpu #whether to calculate in GPU\n",
    "        params_net['size1'] = 49\n",
    "        params_net['size2'] = 60\n",
    "\n",
    "    else:\n",
    "        params_net['layers'] = 5 #1 #2 #3 #4 #5 #6 #7 #8 #9 #10\n",
    "        params_net['kernel'] = [(3, 1)] * 3 + [(3, 1)] * 7\n",
    "        params_net['initial_mu_inverse'] = 0.0\n",
    "\n",
    "        params_net['initial_y1']= 0.8\n",
    "\n",
    "        params_net['coef_mu_inverse'] = 0.36\n",
    "\n",
    "        params_net['CalInGPU'] = gpu # whether to calculate in GPU\n",
    "        params_net['kernel'] = params_net['kernel'][0:params_net['layers']]\n",
    "        params_net['rank'] = 10\n",
    "        params_net['size1'] = 150\n",
    "        params_net['size2'] = 300\n",
    "\n",
    "    return params_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bmMuNqIs97hm",
    "outputId": "8f1d11d7-93d0-4c7e-af2f-2344f492e0ea",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Name: ConvMC-Net_Sampling20.0%_GMM5.0\n",
      "Configuring Network...\n",
      "\n",
      "Instantiating Model...\n",
      "\n",
      "Model Instantiated...\n",
      "\n",
      "Model Configured...\n",
      "\n",
      "Parameters = \n",
      "{'layers': 5, 'kernel': [(3, 1), (3, 1), (3, 1), (3, 1), (3, 1)], 'initial_mu_inverse': 0.0, 'initial_y1': 0.8, 'coef_mu_inverse': 0.36, 'CalInGPU': False, 'rank': 10, 'size1': 150, 'size2': 300}\n",
      "\n",
      "Loading Data phase...\n",
      "----------------\n",
      "Finished loading.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Talha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, 2024-05-11 00:32:17, \n",
      "\n",
      "Epoch: 2, 2024-05-11 00:32:50, \n",
      "\n",
      "Epoch: 3, 2024-05-11 00:33:21, \n",
      "\n",
      "Epoch: 4, 2024-05-11 00:33:48, \n",
      "\n",
      "Epoch: 5, 2024-05-11 00:34:41, \n",
      "\n",
      "Loading and calculating training batches...\n",
      "Training time is 54.569508\n",
      "Loading and calculating validation batches...\n",
      "Test time is 15.407120\n",
      "Epoch: 6, 2024-05-11 00:35:51, \n",
      "\n",
      "Epoch: 7, 2024-05-11 00:36:55, \n",
      "\n",
      "Epoch: 8, 2024-05-11 00:38:03, \n",
      "\n",
      "Epoch: 9, 2024-05-11 00:41:32, \n",
      "\n",
      "Epoch: 10, 2024-05-11 00:42:39, \n",
      "\n",
      "Loading and calculating training batches...\n",
      "Training time is 59.029969\n",
      "Loading and calculating validation batches...\n",
      "Test time is 16.636991\n",
      "Epoch: 11, 2024-05-11 00:43:55, \n",
      "\n",
      "Epoch: 12, 2024-05-11 00:44:56, \n",
      "\n",
      "Epoch: 13, 2024-05-11 00:45:38, \n",
      "\n",
      "Epoch: 14, 2024-05-11 00:46:07, \n",
      "\n",
      "Epoch: 15, 2024-05-11 00:46:33, \n",
      "\n",
      "Loading and calculating training batches...\n",
      "Training time is 23.406102\n",
      "Loading and calculating validation batches...\n",
      "Test time is 5.544024\n",
      "Epoch: 16, 2024-05-11 00:47:02, \n",
      "\n",
      "Epoch: 17, 2024-05-11 00:47:30, \n",
      "\n",
      "Epoch: 18, 2024-05-11 00:48:03, \n",
      "\n",
      "Epoch: 19, 2024-05-11 00:48:30, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some settings for visualisation\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Set parameters (including hyperparameters) and setting for saving/logging data\n",
    "\n",
    "hyper_param_net = training.get_hyperparameter_grid('ConvMC-Net', TrainInstances = 20, ValInstances = 10, BatchSize = 20, ValBatchSize = 10, num_epochs = 20, learning_rate = 0.12)\n",
    "\n",
    "params_net = get_default_param(hyper_param_net, False)\n",
    "\n",
    "CalInGPU = params_net['CalInGPU']\n",
    "\n",
    "q_list = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "db_list = [5.0]\n",
    "\n",
    "for q in q_list:\n",
    "  for db in db_list:\n",
    "    ProjectName = hyper_param_net['Model'] + '_' + 'Sampling' + logs_and_results.get_q_str(q) + '_GMM' + logs_and_results.get_noise_str(db)\n",
    "\n",
    "    # Get log file\n",
    "    logfile = logs_and_results.get_modularized_record(ProjectName, q, db, 'Logs', hyper_param_net, params_net, DATA_PATH, SESSION)\n",
    "    log = open(logfile, 'w')\n",
    "    print('Project Name: %s'%ProjectName)\n",
    "    log.write('Project Name: %s\\n'%ProjectName)\n",
    "\n",
    "    # Get Model\n",
    "    net = training.get_model(params_net, hyper_param_net, log)\n",
    "    print('Parameters = \\n%s\\n'%str(params_net))\n",
    "    log.write('params_net=\\n%s\\n\\n'%str(params_net))\n",
    "\n",
    "    #Loading data and creating dataloader for both test and training\n",
    "    print('Loading Data phase...')\n",
    "    print('----------------')\n",
    "    log.write('Loading phase...\\n')\n",
    "    log.write('----------------\\n')\n",
    "    shape_dset = (params_net['size1'], params_net['size2'])\n",
    "    \n",
    "    train_loader, val_loader = dataset_processing.get_dataloaders(params_net = params_net, hyper_param_net = hyper_param_net, sampling_rate = q, db = db, ROOT = DATA_PATH, synthetic = False)\n",
    "\n",
    "    print('Finished loading.\\n')\n",
    "    log.write('Finished loading.\\n\\n')\n",
    "\n",
    "    # Some additional settings for training including loss, optimizer,\n",
    "    floss = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = hyper_param_net['Lr'])\n",
    "    scheduler2 =  torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma = 0.97, verbose = True)\n",
    "\n",
    "    # Array for recording parameter values after each layer for each epoch etc\n",
    "    outputs_L = convmc.to_var(torch.zeros([shape_dset[0], shape_dset[1]]), CalInGPU)\n",
    "    lossmean_vec = np.zeros((hyper_param_net['Epochs'], ))\n",
    "    lossmean_val_vec = np.zeros((hyper_param_net['Epochs'], ))\n",
    "\n",
    "    mu_inverse, y1, exp_L = net.getexp_LS()\n",
    "\n",
    "    mu_inverse_vec = np.zeros((hyper_param_net['Epochs'], net.layers))\n",
    "    y1_vec = np.zeros((hyper_param_net['Epochs'], net.layers,params_net['size1'], params_net['size2']))\n",
    "    exp_L_vec = np.zeros((hyper_param_net['Epochs'], net.layers))\n",
    "\n",
    "    # dummy variable to monitor and record progress for loss\n",
    "    minloss = np.inf\n",
    "\n",
    "    for epoch in range(hyper_param_net['Epochs']):\n",
    "      print(f'Epoch: {epoch + 1}, {logs_and_results.get_current_time()}, \\n')\n",
    "      log.write('\\n' + logs_and_results.get_current_time() + '\\n')\n",
    "\n",
    "      # Train and Test Steps. (Record every 5 epochs)\n",
    "      if (epoch + 1) % 5 == 0:\n",
    "          print('Loading and calculating training batches...')\n",
    "          log.write('Loading and calculating training batches...\\n')\n",
    "          startime = time.time()\n",
    "          loss_mean = training.train_step(net, train_loader, floss, optimizer, CalInGPU, hyper_param_net['TrainInstances'], hyper_param_net['BatchSize'])\n",
    "          endtime = time.time()\n",
    "          print('Training time is %f'%(endtime - startime))\n",
    "          log.write('Training time is %f\\n'%(endtime - startime))\n",
    "\n",
    "          print('Loading and calculating validation batches...')\n",
    "          log.write('Loading and calculating validation batches...\\n')\n",
    "          startime = time.time()\n",
    "          loss_val_mean = training.test_step(net, val_loader, floss, CalInGPU, hyper_param_net['ValInstances'], hyper_param_net['ValBatchSize'])\n",
    "          endtime = time.time()\n",
    "          print('Test time is %f'%(endtime - startime))\n",
    "          log.write('Test time is %f\\n'%(endtime - startime))\n",
    "      else:\n",
    "        loss_mean = training.train_step(net, train_loader, floss, optimizer, CalInGPU, hyper_param_net['TrainInstances'], hyper_param_net['BatchSize'])\n",
    "        loss_val_mean = training.test_step(net, val_loader, floss, CalInGPU, hyper_param_net['ValInstances'], hyper_param_net['ValBatchSize'])\n",
    "\n",
    "      # Update Record and Parameters\n",
    "      lossmean_vec[epoch] = loss_mean\n",
    "      lossmean_val_vec[epoch] = loss_val_mean\n",
    "\n",
    "      mu_inverse, y1, exp_L = net.getexp_LS()\n",
    "\n",
    "      mu_inverse_vec[epoch, :] = mu_inverse\n",
    "      y1_vec[epoch] = y1\n",
    "      exp_L_vec[epoch, :] = exp_L\n",
    "\n",
    "      # Update Log after every 5 epochs. Make a plot of MSE against epochs every 5 epochs. Save Model in whole/dict form every five epochs.\n",
    "      if (epoch + 1) % 20 == 0:\n",
    "        print(f\"Saving Whole Model at Epochs: [{epoch + 1}/{hyper_param_net['Epochs']}]\")\n",
    "        model_whole_path = logs_and_results.get_modularized_record(ProjectName, q, db, 'Saved Models - Whole', hyper_param_net, params_net, DATA_PATH, SESSION, current_epoch = epoch + 1)\n",
    "        # print(model_whole_path)\n",
    "        torch.save(net, model_whole_path)\n",
    "        print(f\"Saving Model Dict at Epochs: [{epoch + 1}/{hyper_param_net['Epochs']}]\")\n",
    "        model_state_dict_path = logs_and_results.get_modularized_record(ProjectName, q, db, 'Saved Models - Dict', hyper_param_net, params_net, DATA_PATH, SESSION, current_epoch = epoch + 1)\n",
    "        # print(model_state_dict_path)\n",
    "        torch.save(net.state_dict(), model_state_dict_path)\n",
    "\n",
    "        print('Epoch [%d/%d], Lossmean:%.5e, Validation lossmean:%.5e'\n",
    "              %(epoch + 1, hyper_param_net['Epochs'], loss_mean, loss_val_mean))\n",
    "        log.write('Epoch [%d/%d], Lossmean:%.5e, Validation lossmean:%.5e\\n'\n",
    "              %(epoch + 1, hyper_param_net['Epochs'], loss_mean, loss_val_mean))\n",
    "        np.set_printoptions(precision = 3)\n",
    "\n",
    "        print('mu_inverse:', mu_inverse)\n",
    "\n",
    "        print('torch.mean(y1)', np.mean(y1))\n",
    "        print('y1:', y1)\n",
    "        print('exp_L:', exp_L)\n",
    "\n",
    "        log.write('mu_inverse: '+ str(mu_inverse)+'\\n')\n",
    "        log.write('y1: '+ str(y1)+'\\n')\n",
    "        log.write('exp_L: '+ str(exp_L) + '\\n')\n",
    "\n",
    "        if True or loss_val_mean<minloss:\n",
    "          print('saved at [epoch%d/%d]'%(epoch + 1, hyper_param_net['Epochs']))\n",
    "          log.write('saved at [epoch%d/%d]\\n' %(epoch + 1, hyper_param_net['Epochs']))\n",
    "          minloss = min(loss_val_mean, minloss)\n",
    "\n",
    "        # Plotting MSE vs Epoch and Saving it\n",
    "\n",
    "        # Get Directory where we have to save the plot\n",
    "        # dir = logs_and_results.get_modularized_record(ProjectName, q, db, 'Plots', hyper_param_net, params_net, SESSION, current_epoch = epoch + 1)\n",
    "        # epochs_vec = np.arange(0, hyper_param_net['Epochs'], 1)\n",
    "        # logs_and_results.plot_and_save_mse_vs_epoch(epochs_vec, lossmean_vec, hyper_param_net, lossmean_val_vec, dir, epoch)\n",
    "\n",
    "        log.write('\\nMin Loss = %.4e'%np.min(lossmean_val_vec)) # Plotting MSE vs Epoch and Saving it\n",
    "        # Get Directory where we have to save the plot\n",
    "        dir = logs_and_results.get_modularized_record(ProjectName, q, db, 'Plots', hyper_param_net, params_net, DATA_PATH, SESSION, current_epoch = epoch + 1)\n",
    "        logs_and_results.plot_and_save_mse_vs_epoch(lossmean_vec, lossmean_val_vec, dir)\n",
    "\n",
    "    # Finish off by observing the minimum loss on validation set\n",
    "\n",
    "    #Print min loss\n",
    "    print('\\nmin Loss = %.4e'%np.min(lossmean_val_vec))\n",
    "    log.write('\\nmin Loss = %.4e\\n'%np.min(lossmean_val_vec))\n",
    "    log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
