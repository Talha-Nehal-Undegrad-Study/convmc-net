{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QkewbYGcurVf",
    "outputId": "4a84caab-79f0-4e45-bd04-b374a9fcb32b"
   },
   "outputs": [],
   "source": [
    "# Deep Learning Libraries\n",
    "# !pip install 'torch==2.0.1+cu117' -f https://download.pytorch.org/whl/torch_stable.html\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Data Manipulation and Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections # A module providing alternative data structures like named tuples, defaultdict, Counter, etc., compared to built-in Python containers.\n",
    "import random\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "# File and System Interaction\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Scientific Computing and Math\n",
    "import scipy\n",
    "from scipy.signal import tukey # A function from SciPy used to generate a Tukey window for signal processing.\n",
    "from scipy.io import loadmat # A function from SciPy used for reading MATLAB data files.\n",
    "import scipy.io as sio # The SciPy I/O module providing functions for working with different file formats.\n",
    "import math\n",
    "import cmath\n",
    "\n",
    "# # Google Colab and Mount Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Date and Time Handling\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Linear Algebra\n",
    "from torch import linalg as LA\n",
    "import importlib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_py_scripts import convmc, dataset_processing, logs_and_results, training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up some global variables\n",
    "\n",
    "# ROOT = '/home/gcf/Desktop/Talha_Nehal Sproj/Tahir Sproj Stuff/SPROJ_ConvMC_Net/Sensor_Data'\n",
    "ROOT = 'C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/convmc-net/'\n",
    "DATA_PATH = ROOT + '/Image_Inpainting_Dataset'\n",
    "TRY = '1st_try'\n",
    "SESSION = 'Session_1'\n",
    "\n",
    "sys.path.append(ROOT + 'image_py_scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'image_py_scripts.dataset_processing' from 'c:\\\\Users\\\\Talha\\\\OneDrive - Higher Education Commission\\\\Documents\\\\GitHub\\\\convmc-net\\\\image_py_scripts\\\\dataset_processing.py'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(convmc)\n",
    "importlib.reload(training)\n",
    "importlib.reload(logs_and_results)\n",
    "importlib.reload(dataset_processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGsjtUu7-iJ5"
   },
   "source": [
    "Testing Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "nOIBCr5gIr8Y"
   },
   "outputs": [],
   "source": [
    "# Get parameters\n",
    "def get_default_param(hyper_param_net, gpu = True):\n",
    "    params_net = {}\n",
    "    if hyper_param_net['Model'] == 'ADMM-Net':\n",
    "        params_net['layers'] = 5\n",
    "\n",
    "        params_net['initial_neta'] = 1.81    # fixed\n",
    "        params_net['initial_lamda1'] = 0.051 # fixed\n",
    "        params_net['initial_lamda2'] = 0.049 # fixed\n",
    "        params_net['initial_v'] = 0\n",
    "\n",
    "        params_net['initial_S'] = 0.05001 #fixed\n",
    "\n",
    "        params_net['initial_P'] = 0.2401 #fixed\n",
    "\n",
    "        params_net['initial_rho'] = 0.1001\n",
    "\n",
    "        params_net['coef_gamma'] = 0.4001\n",
    "\n",
    "        params_net['CalInGPU'] = gpu #whether to calculate in GPU\n",
    "        params_net['size1'] = 49\n",
    "        params_net['size2'] = 60\n",
    "\n",
    "    else:\n",
    "        params_net['layers'] = 5 #1 #2 #3 #4 #5 #6 #7 #8 #9 #10\n",
    "        params_net['kernel'] = [(3, 1)] * 3 + [(3, 1)] * 7\n",
    "        params_net['initial_mu_inverse'] = 0.0\n",
    "\n",
    "        params_net['initial_y1']= 0.8\n",
    "\n",
    "        params_net['coef_mu_inverse'] = 0.36\n",
    "\n",
    "        params_net['CalInGPU'] = gpu # whether to calculate in GPU\n",
    "        params_net['kernel'] = params_net['kernel'][0:params_net['layers']]\n",
    "        params_net['rank'] = 10\n",
    "        params_net['size1'] = 150\n",
    "        params_net['size2'] = 300\n",
    "\n",
    "    return params_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bmMuNqIs97hm",
    "outputId": "8f1d11d7-93d0-4c7e-af2f-2344f492e0ea",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Name: 1st_try_ConvMC-Net_Sampling20.0%_GMM5.0\n",
      "Configuring Network...\n",
      "\n",
      "Instantiating Model...\n",
      "\n",
      "Model Instantiated...\n",
      "\n",
      "Parameters = \n",
      "{'layers': 5, 'kernel': [(3, 1), (3, 1), (3, 1), (3, 1), (3, 1)], 'initial_mu_inverse': 0.0, 'initial_y1': 0.8, 'coef_mu_inverse': 0.36, 'CalInGPU': False, 'rank': 10, 'size1': 150, 'size2': 300}\n",
      "\n",
      "Loading Data phase...\n",
      "----------------\n",
      "Finished loading.\n",
      "\n",
      "Epoch: 1, 2024-04-30 04:08:47, \n",
      "\n",
      "GG\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (300) must match the size of tensor b (500) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 87\u001b[0m\n\u001b[0;32m     85\u001b[0m     log\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest time is \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(endtime \u001b[38;5;241m-\u001b[39m startime))\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 87\u001b[0m   loss_mean, loss_lowrank_mean \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCalInGPU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyper_param_net\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrainInstances\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyper_param_net\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBatchSize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m   loss_val_mean, loss_val_lowrank_mean \u001b[38;5;241m=\u001b[39m training\u001b[38;5;241m.\u001b[39mtest_step(net, val_loader, floss, CalInGPU, hyper_param_net[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValInstances\u001b[39m\u001b[38;5;124m'\u001b[39m], hyper_param_net[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValBatchSize\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Update Record and Parameters\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Talha\\OneDrive - Higher Education Commission\\Documents\\GitHub\\convmc-net\\image_py_scripts\\training.py:95\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(model, dataloader, loss_fn, optimizer, CalInGPU, TrainInstances, batch, inference)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Forward + backward + loss\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGG\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 95\u001b[0m lst_1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     97\u001b[0m outputs_L \u001b[38;5;241m=\u001b[39m lst_1[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Talha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Talha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/convmc-net/image_py_scripts\\convmc.py:231\u001b[0m, in \u001b[0;36mUnfoldedNet2dC_convmc.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# entries_mask = ~(torch.isnan(data[0]))\u001b[39;00m\n\u001b[0;32m    230\u001b[0m entries_mask \u001b[38;5;241m=\u001b[39m (data[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 231\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentries_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m data \u001b[38;5;241m=\u001b[39m ans[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ans\n",
      "File \u001b[1;32mc:\\Users\\Talha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Talha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Talha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Talha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Talha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/convmc-net/image_py_scripts\\convmc.py:361\u001b[0m, in \u001b[0;36mISTACell_convmc.forward\u001b[1;34m(self, lst)\u001b[0m\n\u001b[0;32m    359\u001b[0m part2_eq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(torch\u001b[38;5;241m.\u001b[39mwhere(entries_mask, L, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m, device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), requires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCalInGPU)))\n\u001b[0;32m    360\u001b[0m \u001b[38;5;66;03m# Part 3: Performs element wise multiplication between W (scaled by 1/mu) and lagrange multiplier (again first mapped its missing values to 0) + a bias\u001b[39;00m\n\u001b[1;32m--> 361\u001b[0m part3_eq \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentries_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mth_y1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mU\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCalInGPU\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mth_W\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mth_mu_inverse\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m th_B\n\u001b[0;32m    363\u001b[0m \u001b[38;5;66;03m# Overall result:\u001b[39;00m\n\u001b[0;32m    364\u001b[0m Ltmp \u001b[38;5;241m=\u001b[39m part1_eq \u001b[38;5;241m+\u001b[39m part2_eq \u001b[38;5;241m+\u001b[39m part3_eq \u001b[38;5;66;03m# shape (49, 60)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (300) must match the size of tensor b (500) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Some settings for visualisation\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Set parameters (including hyperparameters) and setting for saving/logging data\n",
    "\n",
    "hyper_param_net = training.get_hyperparameter_grid('ConvMC-Net', TrainInstances = 20, ValInstances = 10, BatchSize = 5, ValBatchSize = 2, num_epochs = 20, learning_rate = 0.012)\n",
    "\n",
    "params_net = get_default_param(hyper_param_net, False)\n",
    "\n",
    "CalInGPU = params_net['CalInGPU']\n",
    "\n",
    "q_list = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "db_list = [5.0]\n",
    "\n",
    "for q in q_list:\n",
    "  for db in db_list:\n",
    "    ProjectName = TRY + '_' + hyper_param_net['Model'] + '_' + 'Sampling' + logs_and_results.get_q_str(q) + '_GMM' + logs_and_results.get_noise_str(db)\n",
    "\n",
    "    # Get log file\n",
    "    logfile = logs_and_results.get_modularized_record(ProjectName, q, db, 'Logs', hyper_param_net, params_net, DATA_PATH, SESSION)\n",
    "    log = open(logfile, 'w')\n",
    "    print('Project Name: %s'%ProjectName)\n",
    "    log.write('Project Name: %s\\n'%ProjectName)\n",
    "\n",
    "    # Get Model\n",
    "    net = training.get_model(params_net, hyper_param_net, log)\n",
    "    print('Parameters = \\n%s\\n'%str(params_net))\n",
    "    log.write('params_net=\\n%s\\n\\n'%str(params_net))\n",
    "\n",
    "    #Loading data and creating dataloader for both test and training\n",
    "    print('Loading Data phase...')\n",
    "    print('----------------')\n",
    "    log.write('Loading phase...\\n')\n",
    "    log.write('----------------\\n')\n",
    "    shape_dset = (params_net['size1'], params_net['size2'])\n",
    "    \n",
    "    train_loader, val_loader = dataset_processing.get_dataloaders(params_net = params_net, hyper_param_net = hyper_param_net, sampling_rate = q, db = db, ROOT = DATA_PATH)\n",
    "\n",
    "    print('Finished loading.\\n')\n",
    "    log.write('Finished loading.\\n\\n');\n",
    "\n",
    "    # Some additional settings for training including loss, optimizer,\n",
    "    floss = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = hyper_param_net['Lr'])\n",
    "    scheduler2 =  torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma = 0.97, verbose = True)\n",
    "\n",
    "    # Array for recording parameter values after each layer for each epoch etc\n",
    "    outputs_L = convmc.to_var(torch.zeros([shape_dset[0], shape_dset[1]]), CalInGPU)\n",
    "    lossmean_vec = np.zeros((hyper_param_net['Epochs'], ))\n",
    "    lossmean_val_vec = np.zeros((hyper_param_net['Epochs'], ))\n",
    "\n",
    "    mu_inverse, y1, exp_L = net.getexp_LS()\n",
    "\n",
    "    mu_inverse_vec = np.zeros((hyper_param_net['Epochs'], net.layers))\n",
    "    y1_vec = np.zeros((hyper_param_net['Epochs'], net.layers,params_net['size1'], params_net['size2']))\n",
    "    exp_L_vec = np.zeros((hyper_param_net['Epochs'], net.layers))\n",
    "\n",
    "    # dummy variable to monitor and record progress for loss\n",
    "    minloss = np.inf\n",
    "\n",
    "    for epoch in range(hyper_param_net['Epochs']):\n",
    "      print(f'Epoch: {epoch + 1}, {logs_and_results.get_current_time()}, \\n')\n",
    "      log.write('\\n' + logs_and_results.get_current_time() + '\\n')\n",
    "\n",
    "      # Train and Test Steps. (Record every 5 epochs)\n",
    "      if (epoch + 1) % 5 == 0:\n",
    "          print('Loading and calculating training batches...')\n",
    "          log.write('Loading and calculating training batches...\\n')\n",
    "          startime = time.time()\n",
    "          loss_mean, loss_lowrank_mean = training.train_step(net, train_loader, floss, optimizer, CalInGPU, hyper_param_net['TrainInstances'], hyper_param_net['BatchSize'])\n",
    "          endtime = time.time()\n",
    "          print('Training time is %f'%(endtime - startime))\n",
    "          log.write('Training time is %f\\n'%(endtime - startime))\n",
    "\n",
    "          print('Loading and calculating validation batches...')\n",
    "          log.write('Loading and calculating validation batches...\\n')\n",
    "          startime = time.time()\n",
    "          loss_val_mean, loss_val_lowrank_mean = training.test_step(net, val_loader, floss, CalInGPU, hyper_param_net['ValInstances'], hyper_param_net['ValBatchSize'])\n",
    "          endtime = time.time()\n",
    "          print('Test time is %f'%(endtime - startime))\n",
    "          log.write('Test time is %f\\n'%(endtime - startime))\n",
    "      else:\n",
    "        loss_mean, loss_lowrank_mean = training.train_step(net, train_loader, floss, optimizer, CalInGPU, hyper_param_net['TrainInstances'], hyper_param_net['BatchSize'])\n",
    "        loss_val_mean, loss_val_lowrank_mean = training.test_step(net, val_loader, floss, CalInGPU, hyper_param_net['ValInstances'], hyper_param_net['ValBatchSize'])\n",
    "\n",
    "      # Update Record and Parameters\n",
    "      lossmean_vec[epoch] = loss_mean\n",
    "      lossmean_val_vec[epoch] = loss_val_mean\n",
    "\n",
    "      mu_inverse, y1, exp_L = net.getexp_LS()\n",
    "\n",
    "      mu_inverse_vec[epoch, :] = mu_inverse\n",
    "      y1_vec[epoch] = y1\n",
    "      exp_L_vec[epoch, :] = exp_L\n",
    "\n",
    "      # Update Log after every 5 epochs. Make a plot of MSE against epochs every 5 epochs. Save Model in whole/dict form every five epochs.\n",
    "      if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Saving Whole Model at Epochs: [{epoch + 1}/{hyper_param_net['Epochs']}]\")\n",
    "        model_whole_path = logs_and_results.get_modularized_record(ProjectName, q, db, 'Saved Models - Whole', hyper_param_net, params_net, SESSION, current_epoch = epoch + 1)\n",
    "        torch.save(net, model_whole_path)\n",
    "        print(f\"Saving Model Dict at Epochs: [{epoch + 1}/{hyper_param_net['Epochs']}]\")\n",
    "        model_state_dict_path = logs_and_results.get_modularized_record(ProjectName, q, db, 'Saved Models - Dict', hyper_param_net, params_net, SESSION, current_epoch = epoch + 1)\n",
    "        torch.save(net.state_dict(), model_state_dict_path)\n",
    "\n",
    "        print('Epoch [%d/%d], Lossmean:%.5e, Validation lossmean:%.5e'\n",
    "              %(epoch + 1, hyper_param_net['Epochs'], loss_mean, loss_val_mean))\n",
    "        print('loss_lowrank_mean', loss_lowrank_mean)\n",
    "        print('loss_val_lowrank_mean', loss_val_lowrank_mean)\n",
    "\n",
    "        log.write('loss_lowrank_mean %.5e\\n' %(loss_lowrank_mean))\n",
    "        log.write('loss_val_lowrank_mean %.5e\\n' %(loss_val_lowrank_mean))\n",
    "        log.write('Epoch [%d/%d], Lossmean:%.5e, Validation lossmean:%.5e\\n'\n",
    "              %(epoch + 1, hyper_param_net['Epochs'], loss_mean, loss_val_mean))\n",
    "        np.set_printoptions(precision = 3)\n",
    "\n",
    "        print('mu_inverse:', mu_inverse)\n",
    "\n",
    "        print('torch.mean(y1)', np.mean(y1))\n",
    "        print('y1:', y1)\n",
    "        print('exp_L:', exp_L)\n",
    "\n",
    "        log.write('mu_inverse: '+ str(mu_inverse)+'\\n')\n",
    "        log.write('y1: '+ str(y1)+'\\n')\n",
    "        log.write('exp_L: '+ str(exp_L) + '\\n')\n",
    "\n",
    "        if True or loss_val_mean<minloss:\n",
    "          print('saved at [epoch%d/%d]'%(epoch + 1, hyper_param_net['Epochs']))\n",
    "          log.write('saved at [epoch%d/%d]\\n' %(epoch + 1, hyper_param_net['Epochs']))\n",
    "          minloss = min(loss_val_mean, minloss)\n",
    "\n",
    "        # Plotting MSE vs Epoch and Saving it\n",
    "\n",
    "        # Get Directory where we have to save the plot\n",
    "        # dir = logs_and_results.get_modularized_record(ProjectName, q, db, 'Plots', hyper_param_net, params_net, SESSION, current_epoch = epoch + 1)\n",
    "        # epochs_vec = np.arange(0, hyper_param_net['Epochs'], 1)\n",
    "        # logs_and_results.plot_and_save_mse_vs_epoch(epochs_vec, lossmean_vec, hyper_param_net, lossmean_val_vec, dir, epoch)\n",
    "\n",
    "      log.write('\\nMin Loss = %.4e'%np.min(lossmean_val_vec)) # Plotting MSE vs Epoch and Saving it\n",
    "      # Get Directory where we have to save the plot\n",
    "      dir = logs_and_results.get_modularized_record(ProjectName, q, db, 'Plots', hyper_param_net, params_net, DATA_PATH, SESSION, current_epoch = epoch + 1)\n",
    "      logs_and_results.plot_and_save_mse_vs_epoch(lossmean_vec, lossmean_val_vec, dir)\n",
    "\n",
    "    # Finish off by observing the minimum loss on validation set\n",
    "\n",
    "    #Print min loss\n",
    "    print('\\nmin Loss = %.4e'%np.min(lossmean_val_vec))\n",
    "    log.write('\\nmin Loss = %.4e\\n'%np.min(lossmean_val_vec))\n",
    "    log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
