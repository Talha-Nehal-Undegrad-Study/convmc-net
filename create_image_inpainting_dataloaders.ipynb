{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import glob\n",
    "from skimage import io, color, img_as_float\n",
    "\n",
    "from image_py_scripts import run_image_inpainting\n",
    "\n",
    "import torch.utils.data as data\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path('C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/convmc-net/Image_Inpainting_Data/BSDS300/images')\n",
    "train_dir = ROOT / 'train'\n",
    "test_dir = ROOT / 'test'\n",
    "\n",
    "ground_truth_train_dir = train_dir / 'groundtruth'\n",
    "lowrank_train_dir = train_dir / 'lowrank'\n",
    "\n",
    "ground_truth_test_dir = test_dir / 'groundtruth'\n",
    "lowrank_test_dir = test_dir / 'lowrank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_imgs(split = 'train', shape = (150, 300), sampling_rate = 0.2, dB = 5.0):\n",
    "    if split == 'train':\n",
    "        jpg_files = list(train_dir.glob('*.jpg'))\n",
    "        for idx, img in enumerate(jpg_files):\n",
    "            image = io.imread(img)\n",
    "            image = color.rgb2gray(img_as_float(image))\n",
    "            image = np.resize(image, shape)\n",
    "\n",
    "            np.save(os.path.join(ground_truth_train_dir, f'ground_image_MC_train_{idx}.npy'), image)\n",
    "            \n",
    "            image_lowrank = run_image_inpainting.add_gmm_noise(image = image, per = sampling_rate, dB = dB)\n",
    "            np.save(os.path.join(lowrank_train_dir, f'lowrank_image_MC_train_{idx}.npy'), image_lowrank)\n",
    "    \n",
    "    else:\n",
    "        jpg_files = list(test_dir.glob('*.jpg'))\n",
    "        for idx, img in enumerate(jpg_files):\n",
    "            image = io.imread(img)\n",
    "            image = color.rgb2gray(img_as_float(image))\n",
    "            image = np.resize(image, shape)\n",
    "\n",
    "            np.save(os.path.join(ground_truth_test_dir, f'ground_image_MC_test_{idx}.npy'), image)\n",
    "            \n",
    "            image_lowrank = run_image_inpainting.add_gmm_noise(image = image, per = sampling_rate, dB = dB)\n",
    "            np.save(os.path.join(lowrank_test_dir, f'lowrank_image_MC_test_{idx}.npy'), image_lowrank)\n",
    "\n",
    "\"\"\"\n",
    "Example Usage: make_imgs(split = 'train', shape = (150, 300), sampling_rate = 0.2, dB = 5.0)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44320627, 0.46055922, 0.46194314, ..., 0.37857922, 0.40463137,\n",
       "        0.40379804],\n",
       "       [0.43037804, 0.4272898 , 0.39642235, ..., 0.61461569, 0.56952902,\n",
       "        0.56168588],\n",
       "       [0.59108627, 0.67061882, 0.62327725, ..., 0.61532118, 0.64500431,\n",
       "        0.66770039],\n",
       "       ...,\n",
       "       [0.33893294, 0.34285451, 0.34901608, ..., 0.33698353, 0.33249647,\n",
       "        0.33363529],\n",
       "       [0.34483451, 0.36052078, 0.37285098, ..., 0.35339098, 0.34946941,\n",
       "        0.34664902],\n",
       "       [0.34969961, 0.34549529, 0.33848549, ..., 0.37052078, 0.35875608,\n",
       "        0.35483451]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(os.path.join(train_dir, f'groundtruth/ground_image_MC_train_' + str(0) + '.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(data.Dataset):\n",
    "    def __init__(self, shape, split, path, transform = None):\n",
    "        self.shape = shape\n",
    "        \n",
    "        # TRAIN\n",
    "        if split == 0:\n",
    "            # dummy image loader\n",
    "            images_L = torch.zeros(tuple([200]) + self.shape) # --> shape: (200, shape)\n",
    "            images_D = torch.zeros(tuple([200]) + self.shape) # --> shape: (200, shape)\n",
    "            for n in range(200):\n",
    "                L = np.load(os.path.join(path, f'lowrank/lowrank_image_MC_train_' + str(n) + '.npy'))\n",
    "                D = np.load(os.path.join(path, f'groundtruth/ground_image_MC_train_' + str(n) + '.npy'))\n",
    "                # L, D = preprocess(L, D, None, None, None)\n",
    "\n",
    "                images_L[n] = torch.from_numpy(L)\n",
    "                images_D[n] = torch.from_numpy(D)\n",
    "\n",
    "         # TEST\n",
    "        if split == 1:\n",
    "            images_L = torch.zeros(tuple([100]) + self.shape) # --> shape: (200, shape)\n",
    "            images_D = torch.zeros(tuple([100]) + self.shape) # --> shape: (200, shape)\n",
    "            for n in range(100):\n",
    "                L = np.load(os.path.join(path, f'lowrank/lowrank_image_MC_test_' + str(n) + '.npy'))\n",
    "                D = np.load(os.path.join(path, f'groundtruth/ground_image_MC_test_' + str(n) + '.npy'))\n",
    "                # L, D = preprocess(L, D, None, None, None)\n",
    "\n",
    "                images_L[n] = torch.from_numpy(L)\n",
    "                images_D[n] = torch.from_numpy(D)\n",
    "\n",
    "\n",
    "        self.transform = transform\n",
    "        self.images_L = images_L\n",
    "        self.images_D = images_D\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        L = self.images_L[index]\n",
    "        D = self.images_D[index]\n",
    "        return L, D\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_dataset = ImageDataset((params_net['size1'], params_net['size2']), 0, ROOT)\n",
    "train_loader = data.DataLoader(train_dataset, batch_size = 5, shuffle = True)\n",
    "test_dataset = ImageDataset((params_net['size1'], params_net['size2']), 1, ROOT)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
